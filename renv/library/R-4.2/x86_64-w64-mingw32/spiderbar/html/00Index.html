<!DOCTYPE html>
<html>
<head><title>R: Parse and Test Robots Exclusion Protocol Files and Rules</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body><div class="container">
<h1> Parse and Test Robots Exclusion Protocol Files and Rules
<img class="toplogo" src="../../../doc/html/Rlogo.svg" alt="[R logo]" />
</h1>
<hr/>
<div style="text-align: center;">
<a href="../../../doc/html/packages.html"><img class="arrow" src="../../../doc/html/left.jpg" alt="[Up]" /></a>
<a href="../../../doc/html/index.html"><img class="arrow" src="../../../doc/html/up.jpg" alt="[Top]" /></a>
</div><h2>Documentation for package &lsquo;spiderbar&rsquo; version 0.2.5</h2>

<ul><li><a href="../DESCRIPTION">DESCRIPTION file</a>.</li>
</ul>

<h2>Help Pages</h2>


<table style="width: 100%;">
<tr><td style="width: 25%;"><a href="can_fetch.html">can_fetch</a></td>
<td>Test URL paths against a 'robxp' 'robots.txt' object</td></tr>
<tr><td style="width: 25%;"><a href="crawl_delays.html">crawl_delays</a></td>
<td>Retrieve all agent crawl delay values in a 'robxp' 'robots.txt' object</td></tr>
<tr><td style="width: 25%;"><a href="robxp.html">robxp</a></td>
<td>Parse a 'robots.txt' file &amp; create a 'robxp' object</td></tr>
<tr><td style="width: 25%;"><a href="sitemaps.html">sitemaps</a></td>
<td>Retrieve a character vector of sitemaps from a parsed robots.txt object</td></tr>
<tr><td style="width: 25%;"><a href="spiderbar.html">spiderbar</a></td>
<td>Parse and Test Robots Exclusion Protocol Files and Rules</td></tr>
</table>
</div></body></html>
